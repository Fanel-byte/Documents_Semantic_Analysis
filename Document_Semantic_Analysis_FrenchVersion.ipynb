{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78610f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from gensim import corpora #pip install gensim ou pip install -U gensim\n",
    "from collections import defaultdict\n",
    "from gensim import similarities\n",
    "from gensim import models\n",
    "import json #pip install json\n",
    "import re\n",
    "import string\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop #pip install spacy / try pip install stop-words\n",
    "import mysql.connector #pip install mysql-connector-python-rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03bcd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading json file\n",
    "def load_data(file):\n",
    "    with open (file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f) \n",
    "    return (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b65d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing json file\n",
    "def write_data(file, data):\n",
    "    with open (file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb61862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def database(): #Read Database\n",
    "    db=mysql.connector.connect(host='192.185.4.44',\n",
    "                                           database='veillise_test2',\n",
    "                                           user='veillise_veille2',\n",
    "                                           password='@@@@@@@@@@@@@@')\n",
    "    if db.is_connected():\n",
    "            db_Info = db.get_server_info()\n",
    "            print(\"Connected to MySQL Server version \", db_Info)\n",
    "            cursor = db.cursor()\n",
    "            cursor.execute(\"select database();\")\n",
    "            record = cursor.fetchone()\n",
    "            print(\"You're connected to database: \", record)\n",
    "    \n",
    "\n",
    "    mycursor=db.cursor()\n",
    "    query = \"select id, titre, article, group_nb,lang from articles where lang='French' AND (group_nb = \\\"\\\" OR group_nb IS NULL) AND (created_at > DATE_ADD(NOW(), INTERVAL -36 HOUR));\"\n",
    "\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "    if cursor.rowcount != 0 :\n",
    "        print(\"No. of articles not analyzed \", cursor.rowcount)\n",
    "    data = []\n",
    "    for row in result:\n",
    "        article = {}\n",
    "        article[\"id\"] = row[0]\n",
    "        article[\"titre\"]=row[1]\n",
    "        article[\"lang\"]=row[4]\n",
    "        article[\"group_nb\"]=row[3]\n",
    "        article[\"article\"]=row[2]\n",
    "        data.append(article)\n",
    "        \n",
    "    print(len(data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d3551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r'<[^>]+>')\n",
    "pattern = r'[' + string.punctuation + ']'\n",
    "def Clean_Data(txt):\n",
    "    txt = txt.lower() #Lower text\n",
    "    txt = re.sub(regex,'', txt) #Remove Html syntaxe\n",
    "    txt = re.sub(r'http\\S+', '', txt) #Remove URLs\n",
    "    txt = re.sub(pattern,'', txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1cba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cleaned_data(data): #List of List\n",
    "    for i in range(len(data)):\n",
    "        (data[i])[\"titre\"] = Clean_Data((data[i])[\"titre\"])\n",
    "        (data[i])[\"article\"] =  Clean_Data((data[i])[\"titre\"]) + Clean_Data((data[i])[\"article\"])\n",
    "        \n",
    "    return data #List of List "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b16eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treat data \n",
    "def Treat_Data(data,string): #List of List \n",
    "    #Creating a list of stopwords\n",
    "    #Removing stopwords ( Depends on BD too )\n",
    "    stp = [\"finalement\", \"autres\", \"h\", \"été\", \"est-ce\", \"qu’on\", \"vraiment\" ,\"c’est\" ,\"fera\",\"tags\",\"Tags\"]\n",
    "    stoplist= list(fr_stop)+ stp\n",
    "    txts = [[word for word in document[string].lower().split() if word not in stoplist]for document in data]\n",
    "    #Calculating frequency of each word \n",
    "    frequency = defaultdict(int)\n",
    "    for text in txts:\n",
    "        for token in text:\n",
    "            frequency[token] += 1\n",
    "    #Removing words that appear only once\n",
    "    txts = [[token for token in text if frequency[token] > 1]for text in txts]\n",
    "    #Creating a dictionary\n",
    "    gensim_dictionary = corpora.Dictionary(txts)\n",
    "    #Vectorizing the corpus\n",
    "    gensim_corpus = [gensim_dictionary.doc2bow(text) for text in txts]\n",
    "    return gensim_corpus,gensim_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f51cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSI(gensim_corpus,gensim_dictionary,numtopics): #creating LSI model\n",
    "    lsi = models.LsiModel(gensim_corpus, id2word=gensim_dictionary, num_topics=numtopics)\n",
    "    return lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29066e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''-----Treating the query-------\n",
    "    Query is the document that will be compared to \n",
    "    Doc is an article '''\n",
    "def Treat_Query(doc):\n",
    "    #Creating bow vector\n",
    "    vec_bow = gensim_dictionary.doc2bow(doc.lower().split())\n",
    "    #Converting the query to LSI space\n",
    "    vec_lsi = lsi[vec_bow]  \n",
    "    return vec_lsi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd457df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Similarity(vec_lsi,gensim_corpus,lsi): #Testing similarity\n",
    "    index = similarities.MatrixSimilarity(lsi[gensim_corpus])  \n",
    "    simil = index[vec_lsi]  \n",
    "    simil=sorted(list(enumerate(simil)),key=lambda item: -item[1])\n",
    "    return simil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff46e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Match_Sim(data,simil,nbsim,acc): #Match similar articles with a special id\n",
    "    for doc_position, doc_score in simil:\n",
    "        if doc_score>acc:\n",
    "            (data[doc_position])[\"group_nb\"] = nbsim \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c75443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=database() #Read DataBase\n",
    "write_data(\"./DataFINAL.json\",data)\n",
    "nbsim = 0 #id same articles\n",
    "docs = load_data(\"./DataFINAL.json\") \n",
    "docs = Cleaned_data(docs)\n",
    "gensim_corpus,gensim_dictionary = Treat_Data(docs,\"titre\")\n",
    "lsi = LSI(gensim_corpus,gensim_dictionary,3)\n",
    "for i in range(len(docs)):\n",
    "    if (docs[i])[\"group_nb\"] == 0: \n",
    "        vec_lsi = Treat_Query((docs[i])[\"titre\"])\n",
    "        simil = Similarity(vec_lsi,gensim_corpus,lsi)\n",
    "        if simil[i][1]==0.0:\n",
    "            docs[i][\"group_nb\"]=\"NULL\"\n",
    "        else:\n",
    "            nbsim += 1\n",
    "            docs = Match_Sim(docs,simil,nbsim,0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d239152",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = [] #Just to test the algorithm\n",
    "for i in range(len(docs)):\n",
    "    score.append([docs[i]['group_nb'],docs[i]['id']])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ed3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(docs)):\n",
    "    print((docs[i])['titre'] , ',', (docs[i])['group_nb'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff6518",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=mysql.connector.connect(host='192.185.4.44',\n",
    "                                           database='veillise_test2',\n",
    "                                           user='veillise_veille2',\n",
    "                                           password='veille2@2020@')\n",
    "\n",
    "mycursor = d.cursor()\n",
    "query2 = \"select id, titre, article, group_nb,lang from articles where lang='French' AND (created_at > DATE_ADD(NOW(), INTERVAL -36 HOUR));\"\n",
    "mycursor.execute(query2)\n",
    "myresult = mycursor.fetchall()\n",
    "for x in myresult:\n",
    "    \n",
    "    print(x[0], ':', x[1],'grp nb: ', x[3])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
